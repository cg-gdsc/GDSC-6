{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4260fe4-9e71-4f72-96cb-714fe6c00d83",
   "metadata": {},
   "source": [
    "# Tutorial 3: A First Model\n",
    "\n",
    "After getting a basic understanding of the data in the previous tutorial, we are ready to build the first AI model. In this notebook, we will build and evaluate a simple Random Forest model with the use of one feature extracted from the dataset - the top frequency per sample. We will evaluate our model, gain an understanding of the evaluation metric and submit our first results to the leaderboard!\n",
    "\n",
    "**NOTE:** This notebook does not require a GPU instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648966fc-a2a4-4326-b3f1-8259d086668c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to import required libraries and functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1e3ca-df58-418e-8b76-770c30dfcefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt     # allows creation of insightful plots\n",
    "import numpy as np                  # for performing calculations on numerical arrays\n",
    "import pandas as pd                 # home of the DataFrame construct, _the_ most important object for Data Science\n",
    "import seaborn as sns               # allows creation of insightful plots, but a bit prettier\n",
    "import sys                          # Python system library needed to load custom functions\n",
    "import torchaudio                   # library that will allow us to load the audio files\n",
    "import os                           # for changing the directory\n",
    "\n",
    "from scipy.fft import fft, fftfreq  # functions for calculating the fourier transform and frequencies from audio data\n",
    "from tqdm.auto import tqdm          # library to display progress bar while doing apply on pandas dataframe\n",
    "\n",
    "sys.path.append('../src')\n",
    "pd.set_option('display.max_columns', None) # All the columns in a dataframe are shown \n",
    "tqdm.pandas()                       # integrate tqdm with Pandas\n",
    "# line to render the plots under the code cell that created it\n",
    "%matplotlib inline\n",
    "\n",
    "from eda_utils import plot_spec     # functions to create plots for and from audio data\n",
    "from gdsc_utils import PROJECT_DIR # our root directory\n",
    "os.chdir(PROJECT_DIR) # changing our directory to root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d156a9-f1ff-4e35-9a88-72394214a00a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "Let's start with loading the metadata file with the information about our dataset and use the first audio file as an example to illustrate how we want to extract the top frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a5019-400b-465b-8f35-31dfd66f936b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv('data/metadata.csv') # loading the metadata file\n",
    "example_path = df_metadata.loc[0, 'path'] # getting the first path from the dataset\n",
    "example_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4480c5d-1fa3-4eef-92ea-f30f6d9c1806",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do you guys already miss some EDA work? Let us inspect the spectrogram of this file. We know already that the spectrogram contains information about time and frequency domains. From the plot, we will see how the different frequencies are present in our file across the duration of the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021eb344-6a3a-4726-84d0-32dde3322c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_spec([example_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400c023-b912-4722-8798-5acf2aaad85a",
   "metadata": {},
   "source": [
    "We can see, that at the bottom of the spectrogram, there is some kind of bright green strip that's present during the whole recording. It's probably some kind of noise as insects usually operate at relatively high frequencies. You can go back to the previous notebook and see that this \"noise strip\" is more of a rule than an exception. \n",
    "\n",
    "To focus only on the most important frequencies we will remove everything that is below 300 Hz. We will also take only the first 20 seconds (or less in case the file is shorter) of the recording, as this should be sufficient for a baseline solution.\n",
    "\n",
    "Below you have a function that extracts the most dominant frequency for every audio file. With the help of it, we will process the data as follows:\n",
    "* first load the recording\n",
    "* then take the first 20 seconds\n",
    "* calculate the Fourier Transform to obtain the frequency spectrum \n",
    "* then we filter out the noise below 300 Hz\n",
    "* get the top frequency, which means the frequency with the loudest (with highest amplitude) signal\n",
    "\n",
    "We do not include the function in the *source* modules, as it's likely you will not need it in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d51fa-6cef-4bf3-9cec-8ef465b23848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_peak_frequency(path, freq_threshold=300, n_top=1):\n",
    "    data, sampling_rate = torchaudio.load(path)                                        # loading audio file\n",
    "    data = data[0,:20*sampling_rate].numpy()                                           # Taking the first 20 seconds as it should be enough to hear insects sound\n",
    "    fft_data = fft(data)                                                               # calculating fourier transform\n",
    "    freqs = fftfreq(len(data))                                                         # calculating frequencies \n",
    "    freqs = abs(freqs)                                                                 # we are interested in positive numbers only\n",
    "    index_above = freqs*sampling_rate>freq_threshold                                   # there is a lot of noise near 0 hz, so let's filter out what's below 300Hz, this is a hyperparameter you can play with\n",
    "    peak_coefficient = np.argpartition(np.abs(fft_data[index_above]), -n_top)[-n_top:] # taking the index for top n values\n",
    "    peak_freq = freqs[index_above][peak_coefficient]                                   # using the index to find top n frequencies\n",
    "\n",
    "    return peak_freq * sampling_rate                                                   # We need to multiple it by sampling_rate to get the real frequency values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338adf3-4fd2-4444-aa44-ec1c89527d69",
   "metadata": {},
   "source": [
    "Let's see how the function works in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4cdb9-808b-4a25-8440-38ed87ce0998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_peak_freq = extract_peak_frequency(example_path, freq_threshold=300, n_top=1)\n",
    "example_peak_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77042959-46a9-4e01-95aa-0e04f519f38e",
   "metadata": {},
   "source": [
    "Okay, we can see that the top frequency from all frequencies above the threshold of 300 Hz is equal to 21681.4, which supports the claim that the most predominant frequencies for insects lie in higher ranges.\n",
    "\n",
    "Note that we can customise our function to extract a number of top frequencies. Here is an example with the top 10 frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82782a-2061-48b8-929a-d9e2b8987df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_top_10_freq = extract_peak_frequency(example_path, freq_threshold=300, n_top=10)\n",
    "example_top_10_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850970e6-3df4-464d-93e8-73696e5b236c",
   "metadata": {},
   "source": [
    "Great! We can extract even more top frequencies. For our purpose, we will extract only the top one, but please note that you can extract more and use them as features for the model to see if there is any improvement.\n",
    "\n",
    "Now we will apply our function on our metadata file to create a new feature - the top1 frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13df273-6f8c-4cdd-9a91-179a9f284c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting top1 frequencies per file and storing it in a pandas df\n",
    "df_freqs = df_metadata['path'].progress_apply(lambda x: pd.Series(extract_peak_frequency(x))) \n",
    "# joining the metadata df with the top1 frequency dataframe and renaming the column of newly created feature\n",
    "df_metadata = df_metadata.join(df_freqs).rename({0:'top_frequency'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6023d5e-b211-4edc-8aed-1b962ac5e538",
   "metadata": {},
   "source": [
    "Let's inspect the results below. We can see that our metadata data frame has now one more column at the end called *top_frequency*. It's values show the top frequency extracted from the respective recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef4be8-9e90-4e8a-9d65-a56117039852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664cb0b-ff0b-4c2b-9aae-a6f234d1d71c",
   "metadata": {},
   "source": [
    "As in the last notebook, we can use *.describe* to get a basic understanding of this new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04523c46-ae91-4c97-a303-da80855ad140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_metadata.loc[:, \"top_frequency\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe8266-6ad3-4e23-ac02-9fd177ae3ff2",
   "metadata": {},
   "source": [
    "The range of frequencies is between 300 (our cut-off point) and around 22047. But what's more interesting is the frequency distribution between classes. A big difference between classes would tell us, that indeed, there's some discriminative power in our new variable. A [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) will help us check if tis is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b681588-95fc-476e-9406-a68d5e5ec7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,6))\n",
    "sns.boxplot(data = df_metadata, x = 'species', y = \"top_frequency\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38ed57-e7fc-4b9e-9a70-53b1e7f5ec29",
   "metadata": {},
   "source": [
    "We can see from the above plot that there are some differences in frequencies per class. Hence we can use this to build a first model. It will probably not be great but establish a baseline that we can later improve upon.\n",
    "\n",
    "**Key insights**\n",
    "* Insects operate in high-frequency ranges\n",
    "* The top frequencies between classes vary, which may be helpful to distinguish them from one another\n",
    "\n",
    "**Exercises:**\n",
    "\n",
    "Prepare a separate dataset with:\n",
    "- one feature - top 1 frequency, but with freq_threshold set to 0\n",
    "- ten features - top 10 frequencies, with freq_threshold set to 300\n",
    "- think of other important features that you may include in the model and add them to a separate dataset.\n",
    "\n",
    "Save all the datasets for later. We gonna ask you to run a model on them, submit the results and compare the different preprocessing steps that you used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091d4de-2d84-46e9-aaee-3b22b34fd3d4",
   "metadata": {},
   "source": [
    "## Our first model!\n",
    "\n",
    "Having our dataset ready let's finally prepare a baseline model. For this purpose, we will need to import a [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from [scikit-learn](https://scikit-learn.org/stable/), a go-to library for creating Machine Learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcafaa2-35d1-4663-9ace-62c1047e9da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # importing our first model from the sklearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc34cb6-324f-404b-8637-1aecf45fe1ef",
   "metadata": {},
   "source": [
    "Before modeling, we need to split the dataset into training and validation subsets. Usually, this is done via \"splitters\" like [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) or [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit), but in our case we can just use the split that is already provided in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3a810-75f6-4645-ad49-4cc285461920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_metadata[df_metadata['subset']=='train']\n",
    "df_val = df_metadata[df_metadata['subset']=='validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db860a11-6ff0-49ca-87eb-17229c0f2078",
   "metadata": {},
   "source": [
    "Now we need to create numpy arrays that will contain: the data for training (denoted as X_train), labels of the training data (denoted as y_train), the data for evaluation (denoted as X_val), and the labels of the validation set (denoted as y_val). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011b5f3-0eae-43f9-83de-ccaf82a8c8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train[['top_frequency']].values\n",
    "y_train = df_train['label'].values\n",
    "X_val = df_val[['top_frequency']].values\n",
    "y_val = df_val['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d8b54-6852-48c6-9661-31c67ea19e4b",
   "metadata": {},
   "source": [
    "Let's instantiate our classifier. With the magic of scikit-learn, it is as simple as writing one line of code! We set the random_state parameter to 42, to have reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ca548-c247-41f6-a740-e3ed8abf49c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0b40d-4770-46a3-a035-84f6dae3b49e",
   "metadata": {},
   "source": [
    "The last thing to do for the modeling part is to invoke the method fit on our classifier and pass the train set and its labels so that the model can \"learn\" how to predict the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6f50e-6318-44d0-bf1d-958cc1bc5ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f43547-e07e-4135-a872-c9708937cb16",
   "metadata": {},
   "source": [
    "And done! We just trained our first model! Let's create the predictions of the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9da38-5452-4f5b-bc89-67b24a6fec61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = rfc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81127a49-3fb2-4e88-ac80-e3818a5f8b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c14a9-9978-418b-95ac-62a951e01a75",
   "metadata": {},
   "source": [
    "We just created a vector with all the predicted labels for our validation set. \n",
    "\n",
    "But how do we know that it is good? We need to evaluate it!\n",
    "\n",
    "**Key insights:**\n",
    "* instantiating and training models in scikit-learn is really easy!\n",
    "* the library provides a range of different machine learning models, if this is your first encounter with the library, [go ahead and inspect other possibilities](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) for building models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab7c75-8445-48ed-93a0-2a6fc87dc6da",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For this year's challenge, we decided to use the macro averaged [F1-score](https://en.wikipedia.org/wiki/F-score), to assess how well your models perform. To understand the macro averaged F1-score let's first look at two other important classification metrics - [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall).\n",
    "\n",
    "The easiest way to explain everything would be to take an example of a binary classification. This is a task where we only have two classes and one of them is denoted as \"1\" (or positive) and the other as \"0\" (or negative). In this kind of task, any classifier can predict a label either correctly or not. Taking into account the information about the actual labels we basically have these four scenarios:\n",
    "1. The positive class label was assigned correctly - we call it a True Positive (TP)\n",
    "2. The positive class label was assigned incorrectly - we call it a False Positive (FP)\n",
    "3. The negative class label was assigned correctly - we call it a True Negative (TN)\n",
    "4. The negative class label was assigned incorrectly - we call it a False Negative (FN)\n",
    "\n",
    "The **precision** of a classifier is defined as:\n",
    "$$\n",
    "precision= \\frac{TP}{TP+FP}\n",
    "$$\n",
    "\n",
    "And the **recall** as:\n",
    "$$\n",
    "recall= \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "To put it more simply the precision of a classifier tells us how many true positive predictions we have in the set of all positive predictions of the model. The recall on the other hand tells us how many true positive predictions we have in the set of all positive examples in the dataset.\n",
    "\n",
    "A metric that combines the information about precision and recall is called **F1-score** and is defined as:\n",
    "$$\n",
    "F_1=\\frac{2}{\\frac{1}{precision}+\\frac{1}{recall}}\n",
    "$$\n",
    "\n",
    "which means, that it is a harmonic mean of those two.\n",
    "\n",
    "Hopefully, we have now an understanding of what the F1-score is, but we need to see how that translates to our multiclass scenario.\n",
    "\n",
    "In a multiclass classification task, the F1 score is usually calculated for each class separately, by treating that class as the positive class and the remaining classes as the negative class. Once these \"partial\" F1 scores are calculated we need to somehow aggregate them. In the *macro averaged* scenario we simply take the arithmetic mean of all the \"partial\" F1-scores and obtain a single value. This value will determine your place on the leaderboard!\n",
    "\n",
    "***\n",
    "**Exercise**:\n",
    "\n",
    "Another important metric in classification tasks is **accuracy** - if you've never heard of it try to make research and understand it. Would it be a good metric for our task? Post your thoughts on the Teams channel!\n",
    "***\n",
    "Let's now calculate those metrics in Python. For this, we need to make relevant imports from the scikit-learn library, which may help us to understand how well (or badly) are we performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c64024-db27-42ec-9a83-8de5a1ca1821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support \n",
    "\n",
    "# Recall that y_val contains the *truth* and preds the predictions of our model\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_val, preds, average=\"macro\")\n",
    "acc = accuracy_score(y_val, preds)\n",
    "\n",
    "print(f'precision: {precision:.2f}\\nrecall: {recall:.2f}\\nf1-score:{f1:.2f}\\naccuracy: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54fb929-5cd4-42b4-abbc-884f86cfb425",
   "metadata": {},
   "source": [
    "Ouch! Taking into account that all of those metrics range between 0 (everything is wrong) and 1 (everything is correct) we can see that our first model is not generating good results. Nevertheless, let's examine the results on the test set.\n",
    "\n",
    "**Key insights:**\n",
    "* There is a variety of metrics used for measuring a classifier\n",
    "* For the purpose of this challenge your models will be evaluated based on the F1-score\n",
    "\n",
    "**Exercise:**\n",
    "There are a few other options for baseline models:\n",
    "\n",
    "- A model that always predicts the most frequent class\n",
    "- A model that randomly picks any of the existing classes\n",
    "\n",
    "Implement them and compare the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c14fd-1c94-4369-9547-8e42d8058b92",
   "metadata": {},
   "source": [
    "## Our first submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4e100-633a-4542-b022-f231eeb3fdfd",
   "metadata": {},
   "source": [
    "Let us create a first submission that we can upload on the [GDSC webpage](https://gdsc.ce.capgemini.com/) and see our score on the leaderboard. First, we need to read the test metadata, to have the paths for extracting peak frequency from the wav files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110027b7-7f9d-47fe-88ce-b4aec954a864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_metadata_df = pd.read_csv(\"data/test/metadata.csv\")\n",
    "test_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db42541-1650-4cbb-8453-30df3610ffdf",
   "metadata": {},
   "source": [
    "Like previously we need to use the extract_peak_frequency function to get the top frequency for each file, but we need to add the path to the files, so that we can load them and pass through the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9ea65-99eb-4db9-8e77-b2fab02a63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_metadata_df['file_name'] = test_metadata_df['file_name'].apply(lambda x: f'data/test/{x}')\n",
    "test_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23bcc7-9447-4ce1-ae32-7e60463db932",
   "metadata": {},
   "source": [
    "Done! Now we can pass the data through our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326694e7-0022-481e-8d0c-8e5cef2c7959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting top1 frequencies per file and storing it in a pandas df\n",
    "df_freqs_test = test_metadata_df['file_name'].progress_apply(lambda x: pd.Series(extract_peak_frequency(x))) \n",
    "# joining the metadata df with the top1 frequency dataframe and renaming the column of newly created feature\n",
    "test_metadata_df = test_metadata_df.join(df_freqs_test).rename({0:'top_frequency'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ffe76-9d42-4a9b-b4d7-56ede82db2e3",
   "metadata": {},
   "source": [
    "Now we need to get the newly created feature in the form of a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46e415-2c77-4fb2-9f4b-56937110f883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test_metadata_df[[\"top_frequency\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94b67e-e80d-4149-b84b-618f2b7a8923",
   "metadata": {},
   "source": [
    "And do predictions with our previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840ca19-8b85-456c-a3e1-4c4743912092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_test = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4bf7b-7d1c-4374-951c-094fac5007b6",
   "metadata": {},
   "source": [
    "Done! Let's see the vector of test set predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cce351-759c-41e4-a006-0e44be404509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e344c5-cb87-4dc2-af2a-3efa0167fb69",
   "metadata": {},
   "source": [
    "Everything looks good! We need to add this vector to our test_metadata_df and leave only the columns: **file_name** and **predicted_class_id**. The rest of the columns are redundant. The last step is to save the CSV file in the appropriate location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b77592-916d-4445-9937-874b2c22425d",
   "metadata": {},
   "source": [
    "***\n",
    "**It is important that you name the columns exactly like that, otherwise your score won't appear on the leaderboard!**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457817a8-fa61-48e9-a887-5907fc8c1d45",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efcdcb-39f3-4e05-aabb-48122d01dee6",
   "metadata": {},
   "source": [
    "For this model, we created in the **models** folder the **RandomForestClassifier** subfolder. Let's run the remaining cells to save the CSV file in the appropriate form and the appropriate location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f7006-11cb-46f4-8a17-6a1a92315f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating the column with predictions\n",
    "test_metadata_df['predicted_class_id'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ce4fd-bca0-4018-85f9-9ace39b4e6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can see that there is one reduntant column - top_frequency\n",
    "test_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86611ff-8a0a-4ca4-9b73-c2e14d2c0916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's get rid of the top_frequency column and change paths to file names\n",
    "test_metadata_df.drop('top_frequency', axis=1, inplace=True)\n",
    "test_metadata_df['file_name'] = test_metadata_df['file_name'].apply(lambda x: x.split('/')[-1])\n",
    "test_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f096615-5c53-4c46-9b74-18b62ea6eb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the csv file under the appropriate location. Create the folder if it doesn't exist \n",
    "model_folder_path = \"models/RandomForestClassifier\"\n",
    "if not os.path.exists(model_folder_path):\n",
    "    os.makedirs(model_folder_path)\n",
    "test_metadata_df[['file_name', 'predicted_class_id']].to_csv(f'{model_folder_path}/predictions.csv', index=False) # Index false ensures that we won't write what we have in the index of our df to the csv - this would add an additional column in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb65173-bcd6-4b2a-a622-a3ebf80ae129",
   "metadata": {},
   "source": [
    "And done! We have our CSV file with the predictions ready. Let's upload it via the challenge website and see our results!\n",
    "\n",
    "The score seems to be a bit discouraging ðŸ˜Ÿ But don't worry, you surely can improve this baseline model by doing the following exercise!\n",
    "\n",
    "**Key insights:**\n",
    "* If you want your score to be calculated with our backend functions please be sure to save the file with the predictions with exactly two columns - *file_name* and *predicted_class_id*, otherwise we won't be able to process it\n",
    "* A Random Forest although being a great model is probably not the best one if you aim to win the GDSC, especially if we pass only one feature...\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "The last exercise in this notebook is to try to improve our results from the initial modeling. Hopefully, by now you have prepared your other datasets from the first exercise. Try to fit the same model on the data and see the results. What are the different parameters of the random forest model, inspect the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and try to tweak some hyperparameters. Inspect also the scikit-learn library and try out other models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f259b7-6ceb-4eb3-89a5-59a3234fae6a",
   "metadata": {},
   "source": [
    "***\n",
    "In the next tutorial we'll be using a more advanced and more state-of-the-art algorithm, so stay tuned and in the meantime make sure you understood the metrics used for this challenge! \n",
    "\n",
    "**REMINDER**: After finishing your work remember to shut down the instance."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:425657697824:studio-lifecycle-config/clean-trash"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
